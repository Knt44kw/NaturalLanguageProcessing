{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e65ebda543704f23862adb195abb5221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65458dfb9a0348f09ea50e8d8a080e83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_029f34e13d5b4f7d8dc6309238e91e55",
              "IPY_MODEL_91f112bbaf684a0c8782e61cf4cf8bc9"
            ]
          }
        },
        "65458dfb9a0348f09ea50e8d8a080e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "029f34e13d5b4f7d8dc6309238e91e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1cdcf5eb26234830bb47c9a5242d4ba1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20f541bf3c504dc39a8fc38e6ca4df5e"
          }
        },
        "91f112bbaf684a0c8782e61cf4cf8bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44d875a264a9400f9939361c7311156e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:00&lt;00:00, 647kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7b99e1735f145aea58bac265fb4f713"
          }
        },
        "1cdcf5eb26234830bb47c9a5242d4ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20f541bf3c504dc39a8fc38e6ca4df5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44d875a264a9400f9939361c7311156e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7b99e1735f145aea58bac265fb4f713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27368736eaa14efc9664aac4306dd964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88a07d4255d348c6899074c0f378f51a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6daa11f7336497292f4b9354e96dac9",
              "IPY_MODEL_4b2a74308324406b90d1077eb4afa208"
            ]
          }
        },
        "88a07d4255d348c6899074c0f378f51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6daa11f7336497292f4b9354e96dac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7942c06aad1485c8450bb70d6ab15d9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b5b352707ef4cf0904ead9a7b57adc2"
          }
        },
        "4b2a74308324406b90d1077eb4afa208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76fbb36ba47a4e82ae393979f03ac7d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:20&lt;00:00, 21.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21a6d98640cc4c3c8e624b1797ae8c7a"
          }
        },
        "b7942c06aad1485c8450bb70d6ab15d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b5b352707ef4cf0904ead9a7b57adc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76fbb36ba47a4e82ae393979f03ac7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21a6d98640cc4c3c8e624b1797ae8c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cbd671f0875404f88180e8bdd5a6e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1af35dee234b47dba8dc99684cddc7cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f2f396553344b179f1bb3a3cd8a7a1e",
              "IPY_MODEL_85209b0cfd344a489b53400fdff138c7"
            ]
          }
        },
        "1af35dee234b47dba8dc99684cddc7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f2f396553344b179f1bb3a3cd8a7a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14de5a4cbbb34d0fb7379f5baff61408",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445021143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445021143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d92b2563f6140abab76f50f331a1ff6"
          }
        },
        "85209b0cfd344a489b53400fdff138c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d7f849d80fb499b81cad57d8d1a5f55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:15&lt;00:00, 27.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbc70f73a2554e6fac1dc51a7462fcec"
          }
        },
        "14de5a4cbbb34d0fb7379f5baff61408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d92b2563f6140abab76f50f331a1ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d7f849d80fb499b81cad57d8d1a5f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbc70f73a2554e6fac1dc51a7462fcec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Tz_e2k-SQN"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LL4PukCQIx",
        "outputId": "f700afc7-606e-4a94-f553-b3d389a4ceb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQOdy-RfnDk"
      },
      "source": [
        "import sys\n",
        "sys.path.append(f'/content/drive/My Drive/')\n",
        "import os\n",
        "os.chdir(f'/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8lBgkRue4bm",
        "outputId": "659a1109-6c40-4f65-9664-6eb1bd34fbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fugashi==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/0c/d0bf73e1a90aeb3e696c7741a812d4b86adc31a8a9783cc92c535ae29016/fugashi-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (476kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 9.1MB/s \n",
            "\u001b[?25hCollecting ipadic==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/4e/c459f94d62a0bef89f866857bc51b9105aff236b83928618315b41a26b7b/ipadic-1.0.0.tar.gz (13.4MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4MB 235kB/s \n",
            "\u001b[?25hCollecting logzero==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/24/27295d318ea8976b12cf9cc51d82e7c7129220f6a3cc9e3443df3be8afdb/logzero-1.5.0-py2.py3-none-any.whl\n",
            "Collecting mojimoji==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/0e/eb8297652315519ccc0ca3da9e06f0457d87e27f1000f696ca537914856f/mojimoji-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.0MB/s \n",
            "\u001b[?25hCollecting sentence-transformers==0.3.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/0add07b1eebbbe83e77fb5ac4e72e87046c3fc2c9cb16f7d1cd8c6921a1d/sentence-transformers-0.3.7.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting shap==0.36.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/17/37ee6c79cafbd9bb7423b54e55ea90beec66aa7638664d607bcc28de0bae/shap-0.36.0.tar.gz (319kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 48.0MB/s \n",
            "\u001b[?25hCollecting slicer==0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/46/cf/f37ac7f61214ed044b0df91252ab19376de5587926c5b572f060eb7bf257/slicer-0.0.4-py3-none-any.whl\n",
            "Collecting transformers==3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from shap==0.36.0->-r requirements.txt (line 6)) (1.1.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from shap==0.36.0->-r requirements.txt (line 6)) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1->-r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1->-r requirements.txt (line 8)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1->-r requirements.txt (line 8)) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1->-r requirements.txt (line 8)) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1->-r requirements.txt (line 8)) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.7.2->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->shap==0.36.0->-r requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->shap==0.36.0->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->shap==0.36.0->-r requirements.txt (line 6)) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->shap==0.36.0->-r requirements.txt (line 6)) (50.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1->-r requirements.txt (line 8)) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1->-r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1->-r requirements.txt (line 8)) (2.4.7)\n",
            "Building wheels for collected packages: ipadic, sentence-transformers, shap, sacremoses\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-cp36-none-any.whl size=13556725 sha256=9cb6fdc4547f9520970e9f61e4c2bd23f7d41e090952354ab1b620c630364d94\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/00/d1/0c094a0ce58a77199a0c5801f0ecf510c80f0ecbec27f07d2c\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.7.2-cp36-none-any.whl size=91190 sha256=6092db3673f05d977f2d9908e3a5c1db3fd11fb9d67be62a59636ddd153dea23\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/8f/23/7f93e91176acc7c2d651b54fa9f01e3624a47904145c4d133e\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.36.0-cp36-cp36m-linux_x86_64.whl size=456458 sha256=f2c1cbf01444ba00846b10fb0421f021ddb631242c7c3b1efac50ed44e6afe40\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/15/e1/8f61106790da27e0765aaa6e664550ca2c50ea339099e799f4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=9683ec89a3233f4f12bd1b9d624ec773bf6bd94f2446a2c78205f81eb7d802f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built ipadic sentence-transformers shap sacremoses\n",
            "Installing collected packages: fugashi, ipadic, logzero, mojimoji, tokenizers, sacremoses, sentencepiece, transformers, sentence-transformers, slicer, shap\n",
            "Successfully installed fugashi-1.0.4 ipadic-1.0.0 logzero-1.5.0 mojimoji-0.0.11 sacremoses-0.0.43 sentence-transformers-0.3.7.2 sentencepiece-0.1.91 shap-0.36.0 slicer-0.0.4 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIbixM-XDMOI"
      },
      "source": [
        "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
        "from torchtext.data import Field, Dataset, Example\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from logzero import logger\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import mojimoji\n",
        "import collections\n",
        "import time\n",
        "import random\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpO1nTRiTjmC"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Early stops the training if validation loss doesn't improve after a given patience.\n",
        "    based on: https://github.com/Bjarten/early-stopping-pytorch\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            logger.info(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoIwyC5kTmOU"
      },
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"\n",
        "    pandas DataFrameからtorchtextのdatasetつくる\n",
        "    https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\n",
        "    \"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "         Create a dataset from a pandas dataframe of examples and Fields\n",
        "         Arguments:\n",
        "             examples pd.DataFrame: DataFrame of examples\n",
        "             fields {str: Field}: The Fields to use in this tuple. The\n",
        "                 string is a field name, and the Field is the associated field.\n",
        "             filter_pred (callable or None): use only exanples for which\n",
        "                 filter_pred(example) is true, or use all examples if None.\n",
        "                 Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljbEk2fPTugC"
      },
      "source": [
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "\n",
        "        for key, field in fields.items():\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENF3WS56UCr6"
      },
      "source": [
        "class BertClassifier:\n",
        "    def __init__(self, net_dir=None, tokenizer_dir=None, max_length=512, batch_size=32, num_labels=2, num_epochs=100, random_seed=None):\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.num_labels = num_labels\n",
        "        self.num_epochs = num_epochs\n",
        "        \n",
        "        if random_seed is not None:\n",
        "            self.seed_everything(random_seed)\n",
        "            \n",
        "        if tokenizer_dir is None:\n",
        "          self.tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
        "          # self.tokenizer.save_pretrained('tokenizer_dir') 形態素解析の結果を保存\n",
        "        if net_dir is None:\n",
        "          self.net = BertForSequenceClassification.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\", num_labels=num_labels)\n",
        "          # self.net.save_pretrained('model_dir') モデルを保存\n",
        "        else:\n",
        "            self.net = BertForSequenceClassification.from_pretrained(net_dir)\n",
        "        self.TEXT = torchtext.data.Field(\n",
        "            sequential=True,\n",
        "            tokenize=self.tokenizer_with_preprocessing,\n",
        "            use_vocab=True,\n",
        "            lower=False,\n",
        "            include_lengths=True,\n",
        "            batch_first=True,\n",
        "            fix_length=max_length,\n",
        "            init_token='[CLS]',\n",
        "            eos_token='[SEP]',\n",
        "            pad_token='[PAD]',\n",
        "            unk_token='[UNK]'\n",
        "        )\n",
        "        self.LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "    \n",
        "    def seed_everything(self, seed):\n",
        "        random.seed(seed)\n",
        "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        logger.info('Set random seeds')\n",
        "\n",
        "    def tokenizer_with_preprocessing(self, text):\n",
        "        # 半角、全角の変換\n",
        "        text = mojimoji.han_to_zen(text)\n",
        "        # 改行、半角スペース、全角スペースを削除\n",
        "        text = re.sub('\\r', '', text)\n",
        "        text = re.sub('\\n', '', text)\n",
        "        text = re.sub('　', '', text)\n",
        "        text = re.sub(' ', '', text)\n",
        "        # 数字文字の一律「0」化\n",
        "        text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
        "        ret = self.tokenizer.tokenize(text)\n",
        "        return ret\n",
        "\n",
        "    def _build_vocab(self, ds, min_freq=1):\n",
        "        self.TEXT.build_vocab(ds, min_freq=min_freq)\n",
        "        self.TEXT.vocab.stoi = self.tokenizer.vocab\n",
        "        \n",
        "    def fit(self, train_df, test_df, early_stopping_rounds=10, fine_tuning_type='fast'):\n",
        "        print(\"-------------------------Training Phase----------------------------\\n\")\n",
        "        print('Creating Datasets from pandas dataframes')\n",
        "        train_ds = DataFrameDataset(train_df, fields={'Text': self.TEXT, 'Label': self.LABEL})\n",
        "        test_ds = DataFrameDataset(test_df, fields={'Text': self.TEXT, 'Label': self.LABEL})\n",
        "        logger.info('Creating datasets from  pandas dataframes has finished ')\n",
        "        if not hasattr(self.TEXT, 'vocab'):\n",
        "            self._build_vocab(train_ds, min_freq=1)\n",
        "        \n",
        "        print('Creating dataLoaders')\n",
        "        train_dl = torchtext.data.Iterator(train_ds, batch_size=self.batch_size, train=True)\n",
        "        test_dl = torchtext.data.Iterator(test_ds, batch_size=self.batch_size, train=False, sort=False)\n",
        "        logger.info('Creating dataLoaders has finished ')\n",
        "\n",
        "        dataloaders_dict = {\n",
        "            'train': train_dl,\n",
        "            'test': test_dl\n",
        "        }\n",
        "        if fine_tuning_type == 'fast':\n",
        "            # 1. まず全部を、勾配計算Falseにしてしまう\n",
        "            for name, param in self.net.named_parameters():\n",
        "                param.requires_grad = False\n",
        "            # 2. 最後のBertLayerモジュールを勾配計算ありに変更\n",
        "            for name, param in self.net.bert.encoder.layer[-1].named_parameters():\n",
        "                param.requires_grad = True\n",
        "            # 3. 識別器を勾配計算ありに変更\n",
        "            for name, param in self.net.classifier.named_parameters():\n",
        "                param.requires_grad = True\n",
        "        elif fine_tuning_type == 'full':\n",
        "            for name, param in self.net.named_parameters():\n",
        "                param.requires_grad = True\n",
        "        else:\n",
        "            logger.error('please input fine_tuning_type \"fast\" or \"full\"')\n",
        "            raise ValueError\n",
        "\n",
        "        # 最適化手法の設定\n",
        "        # BERTの元の部分はファインチューニング\n",
        "        optimizer = optim.Adam([\n",
        "            {'params': self.net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "            {'params': self.net.classifier.parameters(), 'lr': 5e-5}\n",
        "        ], betas=(0.9, 0.999))\n",
        "\n",
        "        # 損失関数の設定\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # 学習・検証を実行。\n",
        "        self.net = self._train_model(\n",
        "            self.net, dataloaders_dict, criterion, optimizer, num_epochs=self.num_epochs,\n",
        "            patience=early_stopping_rounds)\n",
        "\n",
        "        return self\n",
        "\n",
        "    @staticmethod\n",
        "    def _train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, patience):\n",
        "\n",
        "        # GPUが使えるかを確認\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "        logger.info(f\"使用デバイス：{device}\")\n",
        "        logger.info('-----start-------')\n",
        "\n",
        "        # ネットワークをGPUへ送る\n",
        "        net.to(device)\n",
        "\n",
        "        # ネットワークがある程度固定であれば、高速化させる\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "        # ミニバッチのサイズ\n",
        "        batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "        # early stopping\n",
        "        # initialize the early_stopping object\n",
        "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "        # epochのループ\n",
        "        for epoch in range(num_epochs):\n",
        "            # epochごとの訓練と検証のループ\n",
        "            for phase in ['train', 'test']:\n",
        "                if phase == 'train':\n",
        "                    net.train()  # モデルを訓練モードに\n",
        "                else:\n",
        "                    net.eval()   # モデルを検証モードに\n",
        "\n",
        "                epoch_loss = 0.0  # epochの損失和\n",
        "                epoch_corrects = 0  # epochの正解数\n",
        "                iteration = 1\n",
        "\n",
        "                # 開始時刻を保存\n",
        "                t_epoch_start = time.time()\n",
        "                t_iter_start = time.time()\n",
        "                predictions = []\n",
        "                ground_truths = []\n",
        "\n",
        "                # データローダーからミニバッチを取り出すループ\n",
        "                for batch in (dataloaders_dict[phase]):\n",
        "                    # batchはTextとLableの辞書型変数\n",
        "\n",
        "                    # GPUが使えるならGPUにデータを送る\n",
        "                    inputs = batch.Text[0].to(device)  # 文章\n",
        "                    labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                    # optimizerを初期化\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # 順伝搬（forward）計算\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                        loss, logit = net(input_ids=inputs, labels=labels)                    \n",
        "                        _, preds = torch.max(logit, axis=1)  # ラベルを予測\n",
        "                        predictions.append(preds.cpu().numpy())\n",
        "                        ground_truths.append(labels.data.cpu().numpy())\n",
        "\n",
        "                        # 訓練時はバックプロパゲーション\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                            if (iteration % 10 == 0):  # 10回の学習を行う終えるたびににlossを表示\n",
        "                                t_iter_finish = time.time()\n",
        "                                duration = t_iter_finish - t_iter_start\n",
        "                                acc = (torch.sum(preds == labels.data))\n",
        "                                t_iter_start = time.time()\n",
        "\n",
        "                        iteration += 1\n",
        "\n",
        "                        # 損失と正解数の合計を更新\n",
        "                        epoch_loss += loss.item() * batch_size\n",
        "                        epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # epochごとのlossと正解率\n",
        "                t_epoch_finish = time.time()\n",
        "                epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "                epoch_acc = epoch_corrects.double(\n",
        "                ) / len(dataloaders_dict[phase].dataset)\n",
        "                if net.num_labels > 2:\n",
        "                    calc_f1_average = 'macro'\n",
        "                else:\n",
        "                    calc_f1_average = 'binary'\n",
        "                epoch_f1_score = f1_score(np.concatenate(np.array(ground_truths)), np.concatenate(np.array(predictions)), average=calc_f1_average)\n",
        "                logger.info('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f} F1-Score: {:4f}'.format(epoch+1, num_epochs,\n",
        "                                                                            phase, epoch_loss, epoch_acc, epoch_f1_score))\n",
        "    \n",
        "                if phase == 'val':\n",
        "                    early_stopping(epoch_loss, net)\n",
        "        \n",
        "                if early_stopping.early_stop:\n",
        "                    logger.info(\"Early stopping\")\n",
        "                    # load the last checkpoint with the best model\n",
        "                    net.load_state_dict(torch.load('checkpoint.pt'))\n",
        "                    return net\n",
        "        \n",
        "                t_epoch_start = time.time()\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        return net\n",
        "    \n",
        "    def predict(self, test_df):\n",
        "        print(\"-------------------------Prediction Phase----------------------------\\n\")\n",
        "        print('Creating dataaet and dataloader from pandas dataframe')\n",
        "        test_ds = DataFrameDataset(test_df, fields={'Text': self.TEXT})\n",
        "        if not hasattr(self.TEXT, 'vocab'):\n",
        "            self._build_vocab(test_ds, min_freq=1)\n",
        "        test_dl = torchtext.data.Iterator(test_ds, batch_size=self.batch_size, train=False, sort=False)\n",
        "        logger.info('Dataset and DataLoader from pandas dataframe has finished')\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logger.info(f\"使用デバイス：{device}\")\n",
        "        logger.info('-----Start Prediction -------')\n",
        "        self.net.eval()\n",
        "        self.net.to(device)\n",
        "\n",
        "        logits = []\n",
        "        for batch in tqdm(test_dl):\n",
        "            inputs = batch.Text[0].to(device)\n",
        "            with torch.set_grad_enabled(False):\n",
        "                logit = self.net(input_ids=inputs)\n",
        "                logit = F.softmax(logit[0], dim=1).cpu().numpy()\n",
        "                logits.append(logit)\n",
        "\n",
        "        y_pred = []\n",
        "        for i in range(len(logits)):\n",
        "            for each_pred_label in logits[i]:\n",
        "                y_pred.append(np.argmax(each_pred_label))\n",
        "\n",
        "        logger.info('------Finished Prediction------')\n",
        "        return np.array(y_pred)\n",
        "        \n",
        "    def predict_proba(self, test_df):\n",
        "        test_ds = DataFrameDataset(test_df, fields={'Text': self.TEXT})\n",
        "        if not hasattr(self.TEXT, 'vocab'):\n",
        "          self._build_vocab(test_ds, min_freq=1)\n",
        "        test_dl = torchtext.data.Iterator(test_ds, batch_size=self.batch_size, train=False, sort=False)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logger.info(f\"使用デバイス：{device}\")\n",
        "        logger.info('-----start-------')\n",
        "        self.net.eval()\n",
        "        self.net.to(device)\n",
        "        \n",
        "        logits = []\n",
        "        for batch in tqdm(test_dl):\n",
        "          inputs = batch.Text[0].to(device)\n",
        "          with torch.set_grad_enabled(False):\n",
        "            logit = self.net(input_ids=inputs)\n",
        "            logit = F.softmax(logit[0], dim=1).cpu().numpy()\n",
        "            logits.append(logit)\n",
        "        \n",
        "        pred_proba = []\n",
        "        for i in range(len(logits)):\n",
        "            for each_pred_proba in logits[i]:\n",
        "                pred_proba.append(each_pred_proba)\n",
        "\n",
        "        logger.info('-----finished-------')\n",
        "        return np.array(pred_proba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwfJA3rNdrUV"
      },
      "source": [
        "import glob\n",
        "\n",
        "# 分類のテスト用コーパスを生成するための関数 \n",
        "def load_livedoor_news_corpus():\n",
        "    # カテゴリー辞書を定義\n",
        "    category = {\n",
        "        \"dokujo-tsushin\": 0,\n",
        "        \"it-life-hack\":1,\n",
        "        \"kaden-channel\": 2,\n",
        "        \"livedoor-homme\": 3,\n",
        "        \"movie-enter\": 4,\n",
        "        \"peachy\": 5,\n",
        "        \"smax\": 6,\n",
        "        \"sports-watch\": 7,\n",
        "        \"topic-news\":8\n",
        "    }\n",
        " \n",
        "    docs  = []\n",
        "    labels = []\n",
        "    \n",
        "    \n",
        "    # 全てのカテゴリーのディレクトリについて実行\n",
        "    for c_name, c_id in category.items():\n",
        "        # ファイルのパスを取得\n",
        "        files = glob.glob(\"/content/drive/My Drive/corpus/text/{c_name}/{c_name}*.txt\".format(c_name=c_name))\n",
        "        # カテゴリー名とファイル数を表示\n",
        "        print(\"category: \", c_name, \", \",  len(files))\n",
        " \n",
        "        # 各記事について、URL、 日付、タイトル、 本文の情報を以下のようにして取得\n",
        "        for file in files:\n",
        "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "                # 改行文字で分割してリストで返す\n",
        "                lines = f.read().splitlines()\n",
        "                # url, 日付、タイトル、本文を取得\n",
        "                url = lines[0]  \n",
        "                datetime = lines[1]   \n",
        "                subject = lines[2] \n",
        "                # 記事中の本文を1行にまとめる\n",
        "                body = \"\".join(lines[3:])\n",
        "                # タイトルと本文をまとめる\n",
        "                text = subject + body\n",
        "  \n",
        "            # textをdocsに追加\n",
        "            docs.append(text)\n",
        "            # c_idをlabelsに追加\n",
        "            labels.append(c_id)\n",
        " \n",
        "    return docs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4Fol7AwoUYQ"
      },
      "source": [
        "if os.path.exists(\"/content/drive/My Drive/corpus/test_corpus_using_livedoor_dataset.csv\"):\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/corpus/test_corpus_using_livedoor_dataset.csv\")\n",
        "else:\n",
        "    docs, labels = load_livedoor_news_corpus()\n",
        "    df_text = pd.DataFrame(docs, columns=[\"Text\"])\n",
        "    df_label = pd.DataFrame(labels, columns=[\"Label\"])\n",
        "    df = pd.concat([df_text, df_label], axis=1)\n",
        "    df.to_csv(\"/content/drive/My Drive/corpus/test_corpus_using_livedoor_dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BpwW_Ghdr5a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3F8Vixifj9r",
        "outputId": "50832438-a5ad-4040-a5d1-6434ff8728da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e65ebda543704f23862adb195abb5221",
            "65458dfb9a0348f09ea50e8d8a080e83",
            "029f34e13d5b4f7d8dc6309238e91e55",
            "91f112bbaf684a0c8782e61cf4cf8bc9",
            "1cdcf5eb26234830bb47c9a5242d4ba1",
            "20f541bf3c504dc39a8fc38e6ca4df5e",
            "44d875a264a9400f9939361c7311156e",
            "b7b99e1735f145aea58bac265fb4f713",
            "27368736eaa14efc9664aac4306dd964",
            "88a07d4255d348c6899074c0f378f51a",
            "c6daa11f7336497292f4b9354e96dac9",
            "4b2a74308324406b90d1077eb4afa208",
            "b7942c06aad1485c8450bb70d6ab15d9",
            "0b5b352707ef4cf0904ead9a7b57adc2",
            "76fbb36ba47a4e82ae393979f03ac7d8",
            "21a6d98640cc4c3c8e624b1797ae8c7a",
            "9cbd671f0875404f88180e8bdd5a6e1d",
            "1af35dee234b47dba8dc99684cddc7cc",
            "3f2f396553344b179f1bb3a3cd8a7a1e",
            "85209b0cfd344a489b53400fdff138c7",
            "14de5a4cbbb34d0fb7379f5baff61408",
            "6d92b2563f6140abab76f50f331a1ff6",
            "0d7f849d80fb499b81cad57d8d1a5f55",
            "cbc70f73a2554e6fac1dc51a7462fcec"
          ]
        }
      },
      "source": [
        "model = BertClassifier(num_labels=len(np.unique(df[\"Label\"])), num_epochs=100)\n",
        "model.fit(train_df, test_df, early_stopping_rounds=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65ebda543704f23862adb195abb5221",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27368736eaa14efc9664aac4306dd964",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbd671f0875404f88180e8bdd5a6e1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------Training Phase----------------------------\n",
            "\n",
            "Creating Datasets from pandas dataframes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 201017 05:11:38 <ipython-input-9-f1de98c0c243>:66] Creating datasets from  pandas dataframes has finished \n",
            "[I 201017 05:11:39 <ipython-input-9-f1de98c0c243>:73] Creating dataLoaders has finished \n",
            "[I 201017 05:11:39 <ipython-input-9-f1de98c0c243>:118] 使用デバイス：cuda\n",
            "[I 201017 05:11:39 <ipython-input-9-f1de98c0c243>:119] -----start-------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating dataLoaders\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 201017 05:15:56 <ipython-input-9-f1de98c0c243>:200] Epoch 1/100 | train |  Loss: 1.1523 Acc: 0.6559 F1-Score: 0.620737\n",
            "[I 201017 05:16:49 <ipython-input-9-f1de98c0c243>:200] Epoch 1/100 | test  |  Loss: 0.5000 Acc: 0.8643 F1-Score: 0.854155\n",
            "[I 201017 05:20:56 <ipython-input-9-f1de98c0c243>:200] Epoch 2/100 | train |  Loss: 0.4092 Acc: 0.8843 F1-Score: 0.876274\n",
            "[I 201017 05:21:49 <ipython-input-9-f1de98c0c243>:200] Epoch 2/100 | test  |  Loss: 0.2853 Acc: 0.9213 F1-Score: 0.916354\n",
            "[I 201017 05:25:56 <ipython-input-9-f1de98c0c243>:200] Epoch 3/100 | train |  Loss: 0.2574 Acc: 0.9296 F1-Score: 0.924051\n",
            "[I 201017 05:26:49 <ipython-input-9-f1de98c0c243>:200] Epoch 3/100 | test  |  Loss: 0.2287 Acc: 0.9355 F1-Score: 0.931431\n",
            "[I 201017 05:30:56 <ipython-input-9-f1de98c0c243>:200] Epoch 4/100 | train |  Loss: 0.1833 Acc: 0.9481 F1-Score: 0.943707\n",
            "[I 201017 05:31:49 <ipython-input-9-f1de98c0c243>:200] Epoch 4/100 | test  |  Loss: 0.1750 Acc: 0.9450 F1-Score: 0.941733\n",
            "[I 201017 05:35:57 <ipython-input-9-f1de98c0c243>:200] Epoch 5/100 | train |  Loss: 0.1302 Acc: 0.9659 F1-Score: 0.963170\n",
            "[I 201017 05:36:50 <ipython-input-9-f1de98c0c243>:200] Epoch 5/100 | test  |  Loss: 0.1700 Acc: 0.9512 F1-Score: 0.948143\n",
            "[I 201017 05:40:58 <ipython-input-9-f1de98c0c243>:200] Epoch 6/100 | train |  Loss: 0.0960 Acc: 0.9732 F1-Score: 0.970403\n",
            "[I 201017 05:41:51 <ipython-input-9-f1de98c0c243>:200] Epoch 6/100 | test  |  Loss: 0.1531 Acc: 0.9573 F1-Score: 0.954275\n",
            "[I 201017 05:45:58 <ipython-input-9-f1de98c0c243>:200] Epoch 7/100 | train |  Loss: 0.0724 Acc: 0.9844 F1-Score: 0.983489\n",
            "[I 201017 05:46:51 <ipython-input-9-f1de98c0c243>:200] Epoch 7/100 | test  |  Loss: 0.1595 Acc: 0.9545 F1-Score: 0.950925\n",
            "[I 201017 05:50:57 <ipython-input-9-f1de98c0c243>:200] Epoch 8/100 | train |  Loss: 0.0595 Acc: 0.9851 F1-Score: 0.983546\n",
            "[I 201017 05:51:51 <ipython-input-9-f1de98c0c243>:200] Epoch 8/100 | test  |  Loss: 0.1527 Acc: 0.9586 F1-Score: 0.955453\n",
            "[I 201017 05:55:57 <ipython-input-9-f1de98c0c243>:200] Epoch 9/100 | train |  Loss: 0.0460 Acc: 0.9883 F1-Score: 0.987623\n",
            "[I 201017 05:56:50 <ipython-input-9-f1de98c0c243>:200] Epoch 9/100 | test  |  Loss: 0.1667 Acc: 0.9539 F1-Score: 0.950695\n",
            "[I 201017 06:00:57 <ipython-input-9-f1de98c0c243>:200] Epoch 10/100 | train |  Loss: 0.0411 Acc: 0.9888 F1-Score: 0.988155\n",
            "[I 201017 06:01:51 <ipython-input-9-f1de98c0c243>:200] Epoch 10/100 | test  |  Loss: 0.1601 Acc: 0.9552 F1-Score: 0.952055\n",
            "[I 201017 06:05:57 <ipython-input-9-f1de98c0c243>:200] Epoch 11/100 | train |  Loss: 0.0362 Acc: 0.9891 F1-Score: 0.988157\n",
            "[I 201017 06:06:50 <ipython-input-9-f1de98c0c243>:200] Epoch 11/100 | test  |  Loss: 0.1578 Acc: 0.9593 F1-Score: 0.956281\n",
            "[I 201017 06:10:58 <ipython-input-9-f1de98c0c243>:200] Epoch 12/100 | train |  Loss: 0.0278 Acc: 0.9937 F1-Score: 0.993554\n",
            "[I 201017 06:11:51 <ipython-input-9-f1de98c0c243>:200] Epoch 12/100 | test  |  Loss: 0.1605 Acc: 0.9613 F1-Score: 0.958460\n",
            "[I 201017 06:15:57 <ipython-input-9-f1de98c0c243>:200] Epoch 13/100 | train |  Loss: 0.0208 Acc: 0.9951 F1-Score: 0.994644\n",
            "[I 201017 06:16:51 <ipython-input-9-f1de98c0c243>:200] Epoch 13/100 | test  |  Loss: 0.1765 Acc: 0.9600 F1-Score: 0.957052\n",
            "[I 201017 06:20:57 <ipython-input-9-f1de98c0c243>:200] Epoch 14/100 | train |  Loss: 0.0194 Acc: 0.9954 F1-Score: 0.995078\n",
            "[I 201017 06:21:50 <ipython-input-9-f1de98c0c243>:200] Epoch 14/100 | test  |  Loss: 0.1875 Acc: 0.9579 F1-Score: 0.954266\n",
            "[I 201017 06:25:58 <ipython-input-9-f1de98c0c243>:200] Epoch 15/100 | train |  Loss: 0.0203 Acc: 0.9944 F1-Score: 0.994346\n",
            "[I 201017 06:26:51 <ipython-input-9-f1de98c0c243>:200] Epoch 15/100 | test  |  Loss: 0.1629 Acc: 0.9600 F1-Score: 0.956539\n",
            "[I 201017 06:30:58 <ipython-input-9-f1de98c0c243>:200] Epoch 16/100 | train |  Loss: 0.0147 Acc: 0.9963 F1-Score: 0.995947\n",
            "[I 201017 06:31:51 <ipython-input-9-f1de98c0c243>:200] Epoch 16/100 | test  |  Loss: 0.1901 Acc: 0.9607 F1-Score: 0.956809\n",
            "[I 201017 06:35:58 <ipython-input-9-f1de98c0c243>:200] Epoch 17/100 | train |  Loss: 0.0175 Acc: 0.9942 F1-Score: 0.993816\n",
            "[I 201017 06:36:51 <ipython-input-9-f1de98c0c243>:200] Epoch 17/100 | test  |  Loss: 0.1911 Acc: 0.9545 F1-Score: 0.950760\n",
            "[I 201017 06:40:58 <ipython-input-9-f1de98c0c243>:200] Epoch 18/100 | train |  Loss: 0.0185 Acc: 0.9942 F1-Score: 0.993761\n",
            "[I 201017 06:41:51 <ipython-input-9-f1de98c0c243>:200] Epoch 18/100 | test  |  Loss: 0.1847 Acc: 0.9600 F1-Score: 0.956204\n",
            "[I 201017 06:45:59 <ipython-input-9-f1de98c0c243>:200] Epoch 19/100 | train |  Loss: 0.0146 Acc: 0.9954 F1-Score: 0.995155\n",
            "[I 201017 06:46:53 <ipython-input-9-f1de98c0c243>:200] Epoch 19/100 | test  |  Loss: 0.1816 Acc: 0.9600 F1-Score: 0.956884\n",
            "[I 201017 06:51:00 <ipython-input-9-f1de98c0c243>:200] Epoch 20/100 | train |  Loss: 0.0156 Acc: 0.9952 F1-Score: 0.995011\n",
            "[I 201017 06:51:53 <ipython-input-9-f1de98c0c243>:200] Epoch 20/100 | test  |  Loss: 0.2140 Acc: 0.9566 F1-Score: 0.952934\n",
            "[I 201017 06:56:02 <ipython-input-9-f1de98c0c243>:200] Epoch 21/100 | train |  Loss: 0.0138 Acc: 0.9959 F1-Score: 0.995774\n",
            "[I 201017 06:56:55 <ipython-input-9-f1de98c0c243>:200] Epoch 21/100 | test  |  Loss: 0.2150 Acc: 0.9532 F1-Score: 0.950157\n",
            "[I 201017 07:01:03 <ipython-input-9-f1de98c0c243>:200] Epoch 22/100 | train |  Loss: 0.0110 Acc: 0.9968 F1-Score: 0.996506\n",
            "[I 201017 07:01:56 <ipython-input-9-f1de98c0c243>:200] Epoch 22/100 | test  |  Loss: 0.1938 Acc: 0.9586 F1-Score: 0.955162\n",
            "[I 201017 07:06:04 <ipython-input-9-f1de98c0c243>:200] Epoch 23/100 | train |  Loss: 0.0089 Acc: 0.9976 F1-Score: 0.997544\n",
            "[I 201017 07:06:57 <ipython-input-9-f1de98c0c243>:200] Epoch 23/100 | test  |  Loss: 0.2070 Acc: 0.9593 F1-Score: 0.956206\n",
            "[I 201017 07:11:05 <ipython-input-9-f1de98c0c243>:200] Epoch 24/100 | train |  Loss: 0.0104 Acc: 0.9973 F1-Score: 0.996914\n",
            "[I 201017 07:11:58 <ipython-input-9-f1de98c0c243>:200] Epoch 24/100 | test  |  Loss: 0.2196 Acc: 0.9545 F1-Score: 0.951017\n",
            "[I 201017 07:16:06 <ipython-input-9-f1de98c0c243>:200] Epoch 25/100 | train |  Loss: 0.0107 Acc: 0.9968 F1-Score: 0.996573\n",
            "[I 201017 07:17:00 <ipython-input-9-f1de98c0c243>:200] Epoch 25/100 | test  |  Loss: 0.2004 Acc: 0.9586 F1-Score: 0.954997\n",
            "[I 201017 07:21:08 <ipython-input-9-f1de98c0c243>:200] Epoch 26/100 | train |  Loss: 0.0099 Acc: 0.9963 F1-Score: 0.996141\n",
            "[I 201017 07:22:01 <ipython-input-9-f1de98c0c243>:200] Epoch 26/100 | test  |  Loss: 0.2376 Acc: 0.9559 F1-Score: 0.952648\n",
            "[I 201017 07:26:09 <ipython-input-9-f1de98c0c243>:200] Epoch 27/100 | train |  Loss: 0.0120 Acc: 0.9964 F1-Score: 0.996338\n",
            "[I 201017 07:27:02 <ipython-input-9-f1de98c0c243>:200] Epoch 27/100 | test  |  Loss: 0.1983 Acc: 0.9620 F1-Score: 0.959123\n",
            "[I 201017 07:31:10 <ipython-input-9-f1de98c0c243>:200] Epoch 28/100 | train |  Loss: 0.0129 Acc: 0.9968 F1-Score: 0.996385\n",
            "[I 201017 07:32:03 <ipython-input-9-f1de98c0c243>:200] Epoch 28/100 | test  |  Loss: 0.2075 Acc: 0.9627 F1-Score: 0.958856\n",
            "[I 201017 07:36:11 <ipython-input-9-f1de98c0c243>:200] Epoch 29/100 | train |  Loss: 0.0189 Acc: 0.9936 F1-Score: 0.993059\n",
            "[I 201017 07:37:05 <ipython-input-9-f1de98c0c243>:200] Epoch 29/100 | test  |  Loss: 0.2016 Acc: 0.9613 F1-Score: 0.958079\n",
            "[I 201017 07:41:12 <ipython-input-9-f1de98c0c243>:200] Epoch 30/100 | train |  Loss: 0.0078 Acc: 0.9978 F1-Score: 0.997614\n",
            "[I 201017 07:42:05 <ipython-input-9-f1de98c0c243>:200] Epoch 30/100 | test  |  Loss: 0.1997 Acc: 0.9573 F1-Score: 0.953843\n",
            "[I 201017 07:46:12 <ipython-input-9-f1de98c0c243>:200] Epoch 31/100 | train |  Loss: 0.0108 Acc: 0.9968 F1-Score: 0.996703\n",
            "[I 201017 07:47:05 <ipython-input-9-f1de98c0c243>:200] Epoch 31/100 | test  |  Loss: 0.2117 Acc: 0.9613 F1-Score: 0.957144\n",
            "[I 201017 07:51:13 <ipython-input-9-f1de98c0c243>:200] Epoch 32/100 | train |  Loss: 0.0086 Acc: 0.9968 F1-Score: 0.996413\n",
            "[I 201017 07:52:07 <ipython-input-9-f1de98c0c243>:200] Epoch 32/100 | test  |  Loss: 0.2315 Acc: 0.9532 F1-Score: 0.950032\n",
            "[I 201017 07:56:14 <ipython-input-9-f1de98c0c243>:200] Epoch 33/100 | train |  Loss: 0.0084 Acc: 0.9971 F1-Score: 0.996849\n",
            "[I 201017 07:57:07 <ipython-input-9-f1de98c0c243>:200] Epoch 33/100 | test  |  Loss: 0.2252 Acc: 0.9566 F1-Score: 0.953248\n",
            "[I 201017 08:01:15 <ipython-input-9-f1de98c0c243>:200] Epoch 34/100 | train |  Loss: 0.0050 Acc: 0.9985 F1-Score: 0.998426\n",
            "[I 201017 08:02:08 <ipython-input-9-f1de98c0c243>:200] Epoch 34/100 | test  |  Loss: 0.2253 Acc: 0.9600 F1-Score: 0.956753\n",
            "[I 201017 08:06:16 <ipython-input-9-f1de98c0c243>:200] Epoch 35/100 | train |  Loss: 0.0076 Acc: 0.9975 F1-Score: 0.997284\n",
            "[I 201017 08:07:10 <ipython-input-9-f1de98c0c243>:200] Epoch 35/100 | test  |  Loss: 0.2364 Acc: 0.9539 F1-Score: 0.950187\n",
            "[I 201017 08:11:16 <ipython-input-9-f1de98c0c243>:200] Epoch 36/100 | train |  Loss: 0.0084 Acc: 0.9973 F1-Score: 0.996923\n",
            "[I 201017 08:12:10 <ipython-input-9-f1de98c0c243>:200] Epoch 36/100 | test  |  Loss: 0.2223 Acc: 0.9593 F1-Score: 0.956126\n",
            "[I 201017 08:16:17 <ipython-input-9-f1de98c0c243>:200] Epoch 37/100 | train |  Loss: 0.0031 Acc: 0.9997 F1-Score: 0.999622\n",
            "[I 201017 08:17:10 <ipython-input-9-f1de98c0c243>:200] Epoch 37/100 | test  |  Loss: 0.2093 Acc: 0.9607 F1-Score: 0.957507\n",
            "[I 201017 08:21:18 <ipython-input-9-f1de98c0c243>:200] Epoch 38/100 | train |  Loss: 0.0092 Acc: 0.9964 F1-Score: 0.996282\n",
            "[I 201017 08:22:11 <ipython-input-9-f1de98c0c243>:200] Epoch 38/100 | test  |  Loss: 0.2153 Acc: 0.9613 F1-Score: 0.958259\n",
            "[I 201017 08:26:18 <ipython-input-9-f1de98c0c243>:200] Epoch 39/100 | train |  Loss: 0.0059 Acc: 0.9980 F1-Score: 0.997977\n",
            "[I 201017 08:27:11 <ipython-input-9-f1de98c0c243>:200] Epoch 39/100 | test  |  Loss: 0.2322 Acc: 0.9586 F1-Score: 0.955190\n",
            "[I 201017 08:31:19 <ipython-input-9-f1de98c0c243>:200] Epoch 40/100 | train |  Loss: 0.0029 Acc: 0.9992 F1-Score: 0.999179\n",
            "[I 201017 08:32:12 <ipython-input-9-f1de98c0c243>:200] Epoch 40/100 | test  |  Loss: 0.2231 Acc: 0.9607 F1-Score: 0.956285\n",
            "[I 201017 08:36:19 <ipython-input-9-f1de98c0c243>:200] Epoch 41/100 | train |  Loss: 0.0027 Acc: 0.9995 F1-Score: 0.999460\n",
            "[I 201017 08:37:13 <ipython-input-9-f1de98c0c243>:200] Epoch 41/100 | test  |  Loss: 0.2242 Acc: 0.9647 F1-Score: 0.961196\n",
            "[I 201017 08:41:20 <ipython-input-9-f1de98c0c243>:200] Epoch 42/100 | train |  Loss: 0.0037 Acc: 0.9990 F1-Score: 0.998945\n",
            "[I 201017 08:42:13 <ipython-input-9-f1de98c0c243>:200] Epoch 42/100 | test  |  Loss: 0.2194 Acc: 0.9627 F1-Score: 0.958999\n",
            "[I 201017 08:46:20 <ipython-input-9-f1de98c0c243>:200] Epoch 43/100 | train |  Loss: 0.0050 Acc: 0.9985 F1-Score: 0.998500\n",
            "[I 201017 08:47:14 <ipython-input-9-f1de98c0c243>:200] Epoch 43/100 | test  |  Loss: 0.2403 Acc: 0.9593 F1-Score: 0.955407\n",
            "[I 201017 08:51:22 <ipython-input-9-f1de98c0c243>:200] Epoch 44/100 | train |  Loss: 0.0088 Acc: 0.9968 F1-Score: 0.996311\n",
            "[I 201017 08:52:16 <ipython-input-9-f1de98c0c243>:200] Epoch 44/100 | test  |  Loss: 0.2530 Acc: 0.9586 F1-Score: 0.954987\n",
            "[I 201017 08:56:22 <ipython-input-9-f1de98c0c243>:200] Epoch 45/100 | train |  Loss: 0.0076 Acc: 0.9980 F1-Score: 0.997725\n",
            "[I 201017 08:57:15 <ipython-input-9-f1de98c0c243>:200] Epoch 45/100 | test  |  Loss: 0.2348 Acc: 0.9586 F1-Score: 0.955052\n",
            "[I 201017 09:01:23 <ipython-input-9-f1de98c0c243>:200] Epoch 46/100 | train |  Loss: 0.0067 Acc: 0.9976 F1-Score: 0.997497\n",
            "[I 201017 09:02:17 <ipython-input-9-f1de98c0c243>:200] Epoch 46/100 | test  |  Loss: 0.2318 Acc: 0.9566 F1-Score: 0.954031\n",
            "[I 201017 09:06:24 <ipython-input-9-f1de98c0c243>:200] Epoch 47/100 | train |  Loss: 0.0068 Acc: 0.9975 F1-Score: 0.997332\n",
            "[I 201017 09:07:18 <ipython-input-9-f1de98c0c243>:200] Epoch 47/100 | test  |  Loss: 0.2355 Acc: 0.9613 F1-Score: 0.957962\n",
            "[I 201017 09:11:25 <ipython-input-9-f1de98c0c243>:200] Epoch 48/100 | train |  Loss: 0.0042 Acc: 0.9992 F1-Score: 0.999140\n",
            "[I 201017 09:12:18 <ipython-input-9-f1de98c0c243>:200] Epoch 48/100 | test  |  Loss: 0.2406 Acc: 0.9620 F1-Score: 0.958584\n",
            "[I 201017 09:16:24 <ipython-input-9-f1de98c0c243>:200] Epoch 49/100 | train |  Loss: 0.0051 Acc: 0.9981 F1-Score: 0.997942\n",
            "[I 201017 09:17:18 <ipython-input-9-f1de98c0c243>:200] Epoch 49/100 | test  |  Loss: 0.2486 Acc: 0.9573 F1-Score: 0.953484\n",
            "[I 201017 09:21:25 <ipython-input-9-f1de98c0c243>:200] Epoch 50/100 | train |  Loss: 0.0051 Acc: 0.9981 F1-Score: 0.997986\n",
            "[I 201017 09:22:18 <ipython-input-9-f1de98c0c243>:200] Epoch 50/100 | test  |  Loss: 0.2729 Acc: 0.9559 F1-Score: 0.952878\n",
            "[I 201017 09:26:25 <ipython-input-9-f1de98c0c243>:200] Epoch 51/100 | train |  Loss: 0.0063 Acc: 0.9978 F1-Score: 0.997462\n",
            "[I 201017 09:27:18 <ipython-input-9-f1de98c0c243>:200] Epoch 51/100 | test  |  Loss: 0.2590 Acc: 0.9586 F1-Score: 0.955604\n",
            "[I 201017 09:31:26 <ipython-input-9-f1de98c0c243>:200] Epoch 52/100 | train |  Loss: 0.0045 Acc: 0.9986 F1-Score: 0.998653\n",
            "[I 201017 09:32:19 <ipython-input-9-f1de98c0c243>:200] Epoch 52/100 | test  |  Loss: 0.2700 Acc: 0.9559 F1-Score: 0.952839\n",
            "[I 201017 09:36:26 <ipython-input-9-f1de98c0c243>:200] Epoch 53/100 | train |  Loss: 0.0051 Acc: 0.9988 F1-Score: 0.998761\n",
            "[I 201017 09:37:19 <ipython-input-9-f1de98c0c243>:200] Epoch 53/100 | test  |  Loss: 0.2932 Acc: 0.9545 F1-Score: 0.950520\n",
            "[I 201017 09:41:26 <ipython-input-9-f1de98c0c243>:200] Epoch 54/100 | train |  Loss: 0.0070 Acc: 0.9971 F1-Score: 0.997044\n",
            "[I 201017 09:42:19 <ipython-input-9-f1de98c0c243>:200] Epoch 54/100 | test  |  Loss: 0.2387 Acc: 0.9593 F1-Score: 0.955824\n",
            "[I 201017 09:46:26 <ipython-input-9-f1de98c0c243>:200] Epoch 55/100 | train |  Loss: 0.0024 Acc: 0.9990 F1-Score: 0.998921\n",
            "[I 201017 09:47:19 <ipython-input-9-f1de98c0c243>:200] Epoch 55/100 | test  |  Loss: 0.2561 Acc: 0.9627 F1-Score: 0.958771\n",
            "[I 201017 09:51:26 <ipython-input-9-f1de98c0c243>:200] Epoch 56/100 | train |  Loss: 0.0078 Acc: 0.9975 F1-Score: 0.997517\n",
            "[I 201017 09:52:19 <ipython-input-9-f1de98c0c243>:200] Epoch 56/100 | test  |  Loss: 0.2773 Acc: 0.9566 F1-Score: 0.953099\n",
            "[I 201017 09:56:25 <ipython-input-9-f1de98c0c243>:200] Epoch 57/100 | train |  Loss: 0.0067 Acc: 0.9983 F1-Score: 0.998057\n",
            "[I 201017 09:57:19 <ipython-input-9-f1de98c0c243>:200] Epoch 57/100 | test  |  Loss: 0.2230 Acc: 0.9647 F1-Score: 0.960959\n",
            "[I 201017 10:01:26 <ipython-input-9-f1de98c0c243>:200] Epoch 58/100 | train |  Loss: 0.0060 Acc: 0.9986 F1-Score: 0.998663\n",
            "[I 201017 10:02:19 <ipython-input-9-f1de98c0c243>:200] Epoch 58/100 | test  |  Loss: 0.2258 Acc: 0.9627 F1-Score: 0.959368\n",
            "[I 201017 10:06:26 <ipython-input-9-f1de98c0c243>:200] Epoch 59/100 | train |  Loss: 0.0037 Acc: 0.9985 F1-Score: 0.998490\n",
            "[I 201017 10:07:19 <ipython-input-9-f1de98c0c243>:200] Epoch 59/100 | test  |  Loss: 0.2383 Acc: 0.9627 F1-Score: 0.958949\n",
            "[I 201017 10:11:26 <ipython-input-9-f1de98c0c243>:200] Epoch 60/100 | train |  Loss: 0.0098 Acc: 0.9968 F1-Score: 0.996676\n",
            "[I 201017 10:12:19 <ipython-input-9-f1de98c0c243>:200] Epoch 60/100 | test  |  Loss: 0.2652 Acc: 0.9579 F1-Score: 0.953618\n",
            "[I 201017 10:16:26 <ipython-input-9-f1de98c0c243>:200] Epoch 61/100 | train |  Loss: 0.0063 Acc: 0.9976 F1-Score: 0.997429\n",
            "[I 201017 10:17:19 <ipython-input-9-f1de98c0c243>:200] Epoch 61/100 | test  |  Loss: 0.2461 Acc: 0.9593 F1-Score: 0.954979\n",
            "[I 201017 10:21:27 <ipython-input-9-f1de98c0c243>:200] Epoch 62/100 | train |  Loss: 0.0026 Acc: 0.9993 F1-Score: 0.999330\n",
            "[I 201017 10:22:20 <ipython-input-9-f1de98c0c243>:200] Epoch 62/100 | test  |  Loss: 0.2712 Acc: 0.9539 F1-Score: 0.949373\n",
            "[I 201017 10:26:26 <ipython-input-9-f1de98c0c243>:200] Epoch 63/100 | train |  Loss: 0.0075 Acc: 0.9973 F1-Score: 0.997246\n",
            "[I 201017 10:27:20 <ipython-input-9-f1de98c0c243>:200] Epoch 63/100 | test  |  Loss: 0.2454 Acc: 0.9566 F1-Score: 0.952853\n",
            "[I 201017 10:31:27 <ipython-input-9-f1de98c0c243>:200] Epoch 64/100 | train |  Loss: 0.0051 Acc: 0.9985 F1-Score: 0.998382\n",
            "[I 201017 10:32:20 <ipython-input-9-f1de98c0c243>:200] Epoch 64/100 | test  |  Loss: 0.2345 Acc: 0.9634 F1-Score: 0.960007\n",
            "[I 201017 10:36:27 <ipython-input-9-f1de98c0c243>:200] Epoch 65/100 | train |  Loss: 0.0025 Acc: 0.9992 F1-Score: 0.999080\n",
            "[I 201017 10:37:20 <ipython-input-9-f1de98c0c243>:200] Epoch 65/100 | test  |  Loss: 0.2411 Acc: 0.9607 F1-Score: 0.957612\n",
            "[I 201017 10:41:28 <ipython-input-9-f1de98c0c243>:200] Epoch 66/100 | train |  Loss: 0.0019 Acc: 0.9993 F1-Score: 0.999348\n",
            "[I 201017 10:42:21 <ipython-input-9-f1de98c0c243>:200] Epoch 66/100 | test  |  Loss: 0.2707 Acc: 0.9573 F1-Score: 0.953534\n",
            "[I 201017 10:46:28 <ipython-input-9-f1de98c0c243>:200] Epoch 67/100 | train |  Loss: 0.0077 Acc: 0.9975 F1-Score: 0.997466\n",
            "[I 201017 10:47:21 <ipython-input-9-f1de98c0c243>:200] Epoch 67/100 | test  |  Loss: 0.2423 Acc: 0.9586 F1-Score: 0.955394\n",
            "[I 201017 10:51:29 <ipython-input-9-f1de98c0c243>:200] Epoch 68/100 | train |  Loss: 0.0057 Acc: 0.9983 F1-Score: 0.998049\n",
            "[I 201017 10:52:22 <ipython-input-9-f1de98c0c243>:200] Epoch 68/100 | test  |  Loss: 0.2446 Acc: 0.9640 F1-Score: 0.961494\n",
            "[I 201017 10:56:29 <ipython-input-9-f1de98c0c243>:200] Epoch 69/100 | train |  Loss: 0.0055 Acc: 0.9981 F1-Score: 0.997984\n",
            "[I 201017 10:57:23 <ipython-input-9-f1de98c0c243>:200] Epoch 69/100 | test  |  Loss: 0.2517 Acc: 0.9607 F1-Score: 0.957566\n",
            "[I 201017 11:01:30 <ipython-input-9-f1de98c0c243>:200] Epoch 70/100 | train |  Loss: 0.0040 Acc: 0.9986 F1-Score: 0.998594\n",
            "[I 201017 11:02:23 <ipython-input-9-f1de98c0c243>:200] Epoch 70/100 | test  |  Loss: 0.2370 Acc: 0.9640 F1-Score: 0.960989\n",
            "[I 201017 11:06:30 <ipython-input-9-f1de98c0c243>:200] Epoch 71/100 | train |  Loss: 0.0054 Acc: 0.9988 F1-Score: 0.998800\n",
            "[I 201017 11:07:23 <ipython-input-9-f1de98c0c243>:200] Epoch 71/100 | test  |  Loss: 0.2449 Acc: 0.9620 F1-Score: 0.958110\n",
            "[I 201017 11:11:31 <ipython-input-9-f1de98c0c243>:200] Epoch 72/100 | train |  Loss: 0.0047 Acc: 0.9981 F1-Score: 0.997897\n",
            "[I 201017 11:12:24 <ipython-input-9-f1de98c0c243>:200] Epoch 72/100 | test  |  Loss: 0.3006 Acc: 0.9512 F1-Score: 0.947417\n",
            "[I 201017 11:16:31 <ipython-input-9-f1de98c0c243>:200] Epoch 73/100 | train |  Loss: 0.0026 Acc: 0.9992 F1-Score: 0.999023\n",
            "[I 201017 11:17:25 <ipython-input-9-f1de98c0c243>:200] Epoch 73/100 | test  |  Loss: 0.2713 Acc: 0.9607 F1-Score: 0.957590\n",
            "[I 201017 11:21:32 <ipython-input-9-f1de98c0c243>:200] Epoch 74/100 | train |  Loss: 0.0029 Acc: 0.9992 F1-Score: 0.999071\n",
            "[I 201017 11:22:25 <ipython-input-9-f1de98c0c243>:200] Epoch 74/100 | test  |  Loss: 0.2774 Acc: 0.9573 F1-Score: 0.954553\n",
            "[I 201017 11:26:33 <ipython-input-9-f1de98c0c243>:200] Epoch 75/100 | train |  Loss: 0.0072 Acc: 0.9978 F1-Score: 0.997462\n",
            "[I 201017 11:27:26 <ipython-input-9-f1de98c0c243>:200] Epoch 75/100 | test  |  Loss: 0.2837 Acc: 0.9586 F1-Score: 0.954463\n",
            "[I 201017 11:31:32 <ipython-input-9-f1de98c0c243>:200] Epoch 76/100 | train |  Loss: 0.0056 Acc: 0.9985 F1-Score: 0.998267\n",
            "[I 201017 11:32:25 <ipython-input-9-f1de98c0c243>:200] Epoch 76/100 | test  |  Loss: 0.2403 Acc: 0.9593 F1-Score: 0.956196\n",
            "[I 201017 11:36:32 <ipython-input-9-f1de98c0c243>:200] Epoch 77/100 | train |  Loss: 0.0016 Acc: 0.9992 F1-Score: 0.999132\n",
            "[I 201017 11:37:25 <ipython-input-9-f1de98c0c243>:200] Epoch 77/100 | test  |  Loss: 0.2674 Acc: 0.9613 F1-Score: 0.958235\n",
            "[I 201017 11:41:33 <ipython-input-9-f1de98c0c243>:200] Epoch 78/100 | train |  Loss: 0.0024 Acc: 0.9992 F1-Score: 0.999030\n",
            "[I 201017 11:42:26 <ipython-input-9-f1de98c0c243>:200] Epoch 78/100 | test  |  Loss: 0.2794 Acc: 0.9586 F1-Score: 0.955504\n",
            "[I 201017 11:46:33 <ipython-input-9-f1de98c0c243>:200] Epoch 79/100 | train |  Loss: 0.0039 Acc: 0.9990 F1-Score: 0.998763\n",
            "[I 201017 11:47:26 <ipython-input-9-f1de98c0c243>:200] Epoch 79/100 | test  |  Loss: 0.2548 Acc: 0.9586 F1-Score: 0.955014\n",
            "[I 201017 11:51:34 <ipython-input-9-f1de98c0c243>:200] Epoch 80/100 | train |  Loss: 0.0011 Acc: 0.9997 F1-Score: 0.999665\n",
            "[I 201017 11:52:27 <ipython-input-9-f1de98c0c243>:200] Epoch 80/100 | test  |  Loss: 0.2617 Acc: 0.9620 F1-Score: 0.958983\n",
            "[I 201017 11:56:34 <ipython-input-9-f1de98c0c243>:200] Epoch 81/100 | train |  Loss: 0.0018 Acc: 0.9993 F1-Score: 0.999340\n",
            "[I 201017 11:57:28 <ipython-input-9-f1de98c0c243>:200] Epoch 81/100 | test  |  Loss: 0.2665 Acc: 0.9634 F1-Score: 0.960322\n",
            "[I 201017 12:01:34 <ipython-input-9-f1de98c0c243>:200] Epoch 82/100 | train |  Loss: 0.0087 Acc: 0.9973 F1-Score: 0.996892\n",
            "[I 201017 12:02:28 <ipython-input-9-f1de98c0c243>:200] Epoch 82/100 | test  |  Loss: 0.2896 Acc: 0.9518 F1-Score: 0.948404\n",
            "[I 201017 12:06:34 <ipython-input-9-f1de98c0c243>:200] Epoch 83/100 | train |  Loss: 0.0090 Acc: 0.9976 F1-Score: 0.997406\n",
            "[I 201017 12:07:27 <ipython-input-9-f1de98c0c243>:200] Epoch 83/100 | test  |  Loss: 0.2774 Acc: 0.9545 F1-Score: 0.950449\n",
            "[I 201017 12:11:35 <ipython-input-9-f1de98c0c243>:200] Epoch 84/100 | train |  Loss: 0.0051 Acc: 0.9978 F1-Score: 0.997740\n",
            "[I 201017 12:12:28 <ipython-input-9-f1de98c0c243>:200] Epoch 84/100 | test  |  Loss: 0.2729 Acc: 0.9579 F1-Score: 0.955028\n",
            "[I 201017 12:16:35 <ipython-input-9-f1de98c0c243>:200] Epoch 85/100 | train |  Loss: 0.0074 Acc: 0.9976 F1-Score: 0.997582\n",
            "[I 201017 12:17:28 <ipython-input-9-f1de98c0c243>:200] Epoch 85/100 | test  |  Loss: 0.2705 Acc: 0.9579 F1-Score: 0.953836\n",
            "[I 201017 12:21:34 <ipython-input-9-f1de98c0c243>:200] Epoch 86/100 | train |  Loss: 0.0042 Acc: 0.9988 F1-Score: 0.998658\n",
            "[I 201017 12:22:28 <ipython-input-9-f1de98c0c243>:200] Epoch 86/100 | test  |  Loss: 0.2554 Acc: 0.9607 F1-Score: 0.957152\n",
            "[I 201017 12:26:35 <ipython-input-9-f1de98c0c243>:200] Epoch 87/100 | train |  Loss: 0.0006 Acc: 1.0000 F1-Score: 1.000000\n",
            "[I 201017 12:27:29 <ipython-input-9-f1de98c0c243>:200] Epoch 87/100 | test  |  Loss: 0.2644 Acc: 0.9600 F1-Score: 0.956547\n",
            "[I 201017 12:31:35 <ipython-input-9-f1de98c0c243>:200] Epoch 88/100 | train |  Loss: 0.0015 Acc: 0.9995 F1-Score: 0.999462\n",
            "[I 201017 12:32:28 <ipython-input-9-f1de98c0c243>:200] Epoch 88/100 | test  |  Loss: 0.2655 Acc: 0.9613 F1-Score: 0.958453\n",
            "[I 201017 12:36:35 <ipython-input-9-f1de98c0c243>:200] Epoch 89/100 | train |  Loss: 0.0034 Acc: 0.9990 F1-Score: 0.999015\n",
            "[I 201017 12:37:28 <ipython-input-9-f1de98c0c243>:200] Epoch 89/100 | test  |  Loss: 0.2790 Acc: 0.9566 F1-Score: 0.953585\n",
            "[I 201017 12:41:36 <ipython-input-9-f1de98c0c243>:200] Epoch 90/100 | train |  Loss: 0.0035 Acc: 0.9988 F1-Score: 0.998873\n",
            "[I 201017 12:42:29 <ipython-input-9-f1de98c0c243>:200] Epoch 90/100 | test  |  Loss: 0.2746 Acc: 0.9654 F1-Score: 0.961569\n",
            "[I 201017 12:46:36 <ipython-input-9-f1de98c0c243>:200] Epoch 91/100 | train |  Loss: 0.0027 Acc: 0.9995 F1-Score: 0.999465\n",
            "[I 201017 12:47:29 <ipython-input-9-f1de98c0c243>:200] Epoch 91/100 | test  |  Loss: 0.2879 Acc: 0.9566 F1-Score: 0.952793\n",
            "[I 201017 12:51:35 <ipython-input-9-f1de98c0c243>:200] Epoch 92/100 | train |  Loss: 0.0033 Acc: 0.9995 F1-Score: 0.999459\n",
            "[I 201017 12:52:28 <ipython-input-9-f1de98c0c243>:200] Epoch 92/100 | test  |  Loss: 0.2701 Acc: 0.9620 F1-Score: 0.957704\n",
            "[I 201017 12:56:36 <ipython-input-9-f1de98c0c243>:200] Epoch 93/100 | train |  Loss: 0.0070 Acc: 0.9971 F1-Score: 0.997096\n",
            "[I 201017 12:57:29 <ipython-input-9-f1de98c0c243>:200] Epoch 93/100 | test  |  Loss: 0.2652 Acc: 0.9627 F1-Score: 0.958795\n",
            "[I 201017 13:01:35 <ipython-input-9-f1de98c0c243>:200] Epoch 94/100 | train |  Loss: 0.0034 Acc: 0.9992 F1-Score: 0.999078\n",
            "[I 201017 13:02:28 <ipython-input-9-f1de98c0c243>:200] Epoch 94/100 | test  |  Loss: 0.2550 Acc: 0.9620 F1-Score: 0.958537\n",
            "[I 201017 13:06:34 <ipython-input-9-f1de98c0c243>:200] Epoch 95/100 | train |  Loss: 0.0029 Acc: 0.9986 F1-Score: 0.998641\n",
            "[I 201017 13:07:28 <ipython-input-9-f1de98c0c243>:200] Epoch 95/100 | test  |  Loss: 0.2477 Acc: 0.9647 F1-Score: 0.961942\n",
            "[I 201017 13:11:36 <ipython-input-9-f1de98c0c243>:200] Epoch 96/100 | train |  Loss: 0.0009 Acc: 0.9997 F1-Score: 0.999624\n",
            "[I 201017 13:12:29 <ipython-input-9-f1de98c0c243>:200] Epoch 96/100 | test  |  Loss: 0.2748 Acc: 0.9607 F1-Score: 0.957594\n",
            "[I 201017 13:16:36 <ipython-input-9-f1de98c0c243>:200] Epoch 97/100 | train |  Loss: 0.0051 Acc: 0.9985 F1-Score: 0.998491\n",
            "[I 201017 13:17:28 <ipython-input-9-f1de98c0c243>:200] Epoch 97/100 | test  |  Loss: 0.2617 Acc: 0.9634 F1-Score: 0.959569\n",
            "[I 201017 13:21:35 <ipython-input-9-f1de98c0c243>:200] Epoch 98/100 | train |  Loss: 0.0055 Acc: 0.9981 F1-Score: 0.998229\n",
            "[I 201017 13:22:28 <ipython-input-9-f1de98c0c243>:200] Epoch 98/100 | test  |  Loss: 0.2524 Acc: 0.9613 F1-Score: 0.957975\n",
            "[I 201017 13:26:35 <ipython-input-9-f1de98c0c243>:200] Epoch 99/100 | train |  Loss: 0.0020 Acc: 0.9995 F1-Score: 0.999464\n",
            "[I 201017 13:27:29 <ipython-input-9-f1de98c0c243>:200] Epoch 99/100 | test  |  Loss: 0.2495 Acc: 0.9661 F1-Score: 0.963353\n",
            "[I 201017 13:31:35 <ipython-input-9-f1de98c0c243>:200] Epoch 100/100 | train |  Loss: 0.0077 Acc: 0.9981 F1-Score: 0.997780\n",
            "[I 201017 13:32:28 <ipython-input-9-f1de98c0c243>:200] Epoch 100/100 | test  |  Loss: 0.2623 Acc: 0.9647 F1-Score: 0.961150\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.BertClassifier at 0x7f7649d9bf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LenNZn00-rce",
        "outputId": "3dfeadb5-4559-4e48-d0fc-5db7ebaf8ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "y_true = test_df[\"Label\"]\n",
        "y_pred = model.predict(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------Prediction Phase----------------------------\n",
            "\n",
            "Creating dataaet and dataloader from pandas dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 201017 13:32:31 <ipython-input-9-f1de98c0c243>:223] Dataset and DataLoader from pandas dataframe has finished\n",
            "[I 201017 13:32:31 <ipython-input-9-f1de98c0c243>:226] 使用デバイス：cuda\n",
            "[I 201017 13:32:31 <ipython-input-9-f1de98c0c243>:227] -----Start Prediction -------\n",
            "100%|██████████| 47/47 [00:52<00:00,  1.12s/it]\n",
            "[I 201017 13:33:24 <ipython-input-9-f1de98c0c243>:244] ------Finished Prediction------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmrsIiutgfrs",
        "outputId": "fa52f596-0b10-4555-9557-2738cd63919e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "label_names = [\"dokujo-tsushin\", \"it-life-hack\",  \"kaden-channel\", \n",
        "               \"livedoor-homme\", \"movie-enter\",  \"peachy\",\n",
        "               \"smax\", \"sports-watch\",\"topic-news\"]\n",
        "print(\"Acuuracy: {:.4f}\".format(accuracy_score(y_true, y_pred)))\n",
        "print(\"{}\\n\".format(classification_report(y_true=y_true, y_pred=y_pred, target_names = label_names)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuuracy: 0.9647\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.95      0.96      0.95       174\n",
            "  it-life-hack       0.98      0.97      0.97       174\n",
            " kaden-channel       0.97      0.98      0.97       173\n",
            "livedoor-homme       0.92      0.86      0.89       102\n",
            "   movie-enter       0.98      0.97      0.97       174\n",
            "        peachy       0.93      0.93      0.93       169\n",
            "          smax       0.97      0.99      0.98       174\n",
            "  sports-watch       0.99      0.98      0.99       180\n",
            "    topic-news       0.97      0.99      0.98       154\n",
            "\n",
            "      accuracy                           0.96      1474\n",
            "     macro avg       0.96      0.96      0.96      1474\n",
            "  weighted avg       0.96      0.96      0.96      1474\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}